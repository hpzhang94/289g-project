{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hpzhang94/289g-project/blob/main/BiLSTM_TextClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48LTaMV9V-rk",
        "outputId": "0850dc60-ba83-4e57-bf01-2a1294d66c76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import GloVe\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "def getR8():\n",
        "  r8train = pandas.read_csv('/content/drive/MyDrive/Colab Files/R8-lstm/train.txt', sep='\\t', names=['label', 'sentence'])\n",
        "  r8test = pandas.read_csv('/content/drive/MyDrive/Colab Files/R8-lstm/test.txt', sep='\\t', names=['label', 'sentence'])\n",
        "  return r8train, r8test\n",
        "\n",
        "def getMovieReview():\n",
        "  trainX = pandas.read_csv('/content/drive/MyDrive/Colab Files/MovieReview/text_train.txt', sep='\\t', names=['sentence'])\n",
        "  trainY = pandas.read_csv('/content/drive/MyDrive/Colab Files/MovieReview/label_train.txt', sep='\\t', names=['label'])\n",
        "  train = pandas.concat([trainX, trainY], axis=1)\n",
        "  testX = pandas.read_csv('/content/drive/MyDrive/Colab Files/MovieReview/text_test.txt', sep='\\t', names=['sentence'])\n",
        "  testY = pandas.read_csv('/content/drive/MyDrive/Colab Files/MovieReview/label_test.txt', sep='\\t', names=['label'])\n",
        "  test = pandas.concat([testX, testY], axis=1)\n",
        "  return train, test\n",
        "\n",
        "r8train, r8test = getR8()\n",
        "mr_train, mr_test = getMovieReview()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_len_stats(df):\n",
        "  df['length'] = df['sentence'].str.split().str.len()\n",
        "  print(df['length'].describe())\n",
        "get_len_stats(mr_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqP4jUuWsR30",
        "outputId": "9bc44453-36b4-4090-f72b-f41f69f48b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    7108.000000\n",
            "mean       21.000563\n",
            "std         9.396583\n",
            "min         1.000000\n",
            "25%        14.000000\n",
            "50%        20.000000\n",
            "75%        27.000000\n",
            "max        59.000000\n",
            "Name: length, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vocab(df):\n",
        "  counts = 0\n",
        "  vocab = set()\n",
        "  for index, row in df.iterrows():\n",
        "    vocab.update(tokenizer(row['sentence']))\n",
        "  return vocab\n",
        "\n",
        "def load_glove_vectors():\n",
        "  return GloVe(name='840B', dim=300)\n",
        "\n",
        "def get_embedding_matrix(pretrained, vocab, emb_size=300):\n",
        "  \"\"\" Creates embedding matrix from word vectors\"\"\"\n",
        "  vocab_size = len(vocab) + 2\n",
        "  vocab_to_idx = {}\n",
        "  new_vocab = [\"\", \"UNK\"]\n",
        "  W = np.zeros((vocab_size, emb_size), dtype=\"float32\")\n",
        "  W[0] = np.zeros(emb_size, dtype='float32') # adding a vector for padding\n",
        "  W[1] = np.random.uniform(-0.25, 0.25, emb_size) # adding a vector for unknown words \n",
        "  vocab_to_idx[\"UNK\"] = 1\n",
        "  i = 2\n",
        "  for word in vocab:\n",
        "    W[i] = pretrained.get_vecs_by_tokens([word], lower_case_backup=True)[0]\n",
        "    vocab_to_idx[word] = i\n",
        "    new_vocab.append(word)\n",
        "    i += 1   \n",
        "  return W, np.array(new_vocab), vocab_to_idx\n",
        "\n",
        "def encode_sentence(text, vocab_to_idx):\n",
        "  tokens = tokenizer(text)\n",
        "  actual_encoding = np.array([vocab_to_idx.get(word, vocab_to_idx[\"UNK\"]) for word in tokens])\n",
        "  return actual_encoding\n",
        "\n",
        "def df_mapping(df, vocab_to_idx, label_to_idx=None):\n",
        "  ## convert sentence to list of indices\n",
        "  df['encoding'] = df['sentence'].apply(lambda x: encode_sentence(x, vocab_to_idx))\n",
        "  if label_to_idx:\n",
        "    df['Y'] = df['label'].map(label_to_idx)\n",
        "  else:\n",
        "    df['Y'] = df['label']\n",
        "  return df\n",
        "\n",
        "def get_label_mapping(df):\n",
        "  labels = df['label'].unique()\n",
        "  label_to_idx = {labels[i]:i for i in range(len(labels))}\n",
        "  idx_to_label = {i:labels[i] for i in range(len(labels))}\n",
        "  return label_to_idx, idx_to_label\n",
        "\n",
        "# pretrained = load_glove_vectors()\n",
        "\n",
        "# for R8\n",
        "vocab = get_vocab(r8train)\n",
        "print(f'Vocab size is {len(vocab)}')\n",
        "W, vocab2, vocab_to_idx = get_embedding_matrix(pretrained, vocab)\n",
        "label_to_idx, idx_to_label = get_label_mapping(r8train)\n",
        "train_df = df_mapping(r8train, vocab_to_idx, label_to_idx)\n",
        "test_df = df_mapping(r8test, vocab_to_idx, label_to_idx)\n",
        "\n",
        "# for MR\n",
        "# vocab = get_vocab(mr_train)\n",
        "# print(f'Vocab size is {len(vocab)}')\n",
        "# W, vocab2, vocab_to_idx = get_embedding_matrix(pretrained, vocab)\n",
        "# label_to_idx, idx_to_label = get_label_mapping(mr_train)\n",
        "# train_df = df_mapping(mr_train, vocab_to_idx)\n",
        "# test_df = df_mapping(mr_test, vocab_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afzqbz-WoDgj",
        "outputId": "06bec996-878d-4f14-f936-2fc584d229e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size is 19982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred\n",
        "# accuracy_score(test_df['Y'], y_pred)\n",
        "\n",
        "\n",
        "def len_cat(x):\n",
        "  if x < 30: return 'extreme short'\n",
        "  elif x <= 50: return 'short'\n",
        "  elif x <= 70: return 'medium'\n",
        "  else: return 'long'\n",
        "\n",
        "def length_acc(test_df, y_pred):\n",
        "  pred_df = pandas.DataFrame(data={'pred': y_pred, 'label': test_df['Y'], 'length': test_df['sentence'].str.split().str.len()})\n",
        "  pred_df['len'] = pred_df['length'].map(len_cat)\n",
        "  for cat in pred_df['len'].unique():\n",
        "    xdf = pred_df[pred_df['len'] == cat]\n",
        "    print(f\"Accuracy of {cat} = {accuracy_score(xdf['label'], xdf['pred'])}\")\n",
        "  return pred_df\n",
        "\n",
        "pred_df = length_acc(test_df, y_pred)\n",
        "# pred_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM6y9bCoq6Ot",
        "outputId": "09b1c143-81a1-4ac0-e6aa-635ee387c079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of long = 0.9108079748163693\n",
            "Accuracy of medium = 0.9897959183673469\n",
            "Accuracy of extreme short = 0.980349344978166\n",
            "Accuracy of short = 0.987603305785124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate(batch, pad_index=0):\n",
        "    label_list, seq_list, len_list = [], [], []\n",
        "    for (_seq, _label, _len) in batch:\n",
        "      label_list.append(_label)\n",
        "      seq_list.append(torch.tensor(_seq))\n",
        "      len_list.append(_len)\n",
        "    return pad_sequence(seq_list, batch_first=True, padding_value=pad_index), torch.tensor(label_list), torch.tensor(len_list)\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, X, Y):\n",
        "    self.X = X\n",
        "    self.y = Y\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    return torch.from_numpy(self.X[idx].astype(np.int32)), self.y[idx], len(self.X[idx])\n",
        "\n",
        "trainX = list(train_df['encoding'])\n",
        "trainY = list(train_df['Y'])\n",
        "testX = list(test_df['encoding'])\n",
        "testY = list(test_df['Y'])\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
        "train_ds = MyDataset(trainX, trainY)\n",
        "train_dl = DataLoader(train_ds, batch_size=64, collate_fn=collate, shuffle=True)\n",
        "test_ds = MyDataset(testX, testY)\n",
        "test_dl = DataLoader(test_ds, batch_size=64, collate_fn=collate, shuffle=False)"
      ],
      "metadata": {
        "id": "dCk6JD8U7Or4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self, vocab_size, pretrained, label_size, dimension=128):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, 300, padding_idx=0)\n",
        "    if pretrained is not None:\n",
        "      self.embedding.weight.data.copy_(torch.from_numpy(pretrained))\n",
        "      self.embedding.weight.requires_grd = False ## freeze weights\n",
        "    self.dimension = dimension\n",
        "    self.lstm = nn.LSTM(input_size=300, hidden_size=dimension, num_layers=1, batch_first=True, bidirectional=True)\n",
        "    self.drop = nn.Dropout(p=0.2)\n",
        "    self.fc = nn.Linear(dimension*2, label_size)\n",
        "  \n",
        "  def forward(self, text, text_len):\n",
        "    text_emb = self.embedding(text)\n",
        "    packed_input = pack_padded_sequence(text_emb, text_len.cpu(), batch_first=True, enforce_sorted=False)\n",
        "    packed_output, (hidden, cell) = self.lstm(packed_input)\n",
        "\n",
        "    # output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "    # out_forward = output[range(len(output)), text_len - 1, :self.dimension]\n",
        "    # out_reverse = output[:, 0, self.dimension:]\n",
        "    # out_reduced = torch.cat((out_forward, out_reverse), 1) # 64 * 256\n",
        "    # text_fea = self.drop(out_reduced)\n",
        "    text_fea = self.drop(torch.cat((hidden[0,:,:], hidden[1,:,:]), 1)) # 64 * 256, for bidirectional\n",
        "    # text_fea = self.drop(hidden[-1]) # for unidirectional\n",
        "\n",
        "    text_fea = self.fc(text_fea)\n",
        "    text_fea = torch.squeeze(text_fea, 1)\n",
        "    text_out = torch.sigmoid(text_fea)\n",
        "    return text_out\n"
      ],
      "metadata": {
        "id": "PMZ8TZ-NYkvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and Load Functions\n",
        "\n",
        "def save_checkpoint(save_path, model, optimizer, valid_loss):\n",
        "\n",
        "    if save_path == None:\n",
        "        return\n",
        "    \n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'valid_loss': valid_loss}\n",
        "    \n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "\n",
        "def load_checkpoint(load_path, model, optimizer):\n",
        "\n",
        "    if load_path==None:\n",
        "        return\n",
        "    \n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    \n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
        "    \n",
        "    return state_dict['valid_loss']\n",
        "\n",
        "\n",
        "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
        "\n",
        "    if save_path == None:\n",
        "        return\n",
        "    \n",
        "    state_dict = {'train_loss_list': train_loss_list,\n",
        "                  'valid_loss_list': valid_loss_list,\n",
        "                  'global_steps_list': global_steps_list}\n",
        "    \n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "\n",
        "def load_metrics(load_path):\n",
        "\n",
        "    if load_path==None:\n",
        "        return\n",
        "    \n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    \n",
        "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']\n"
      ],
      "metadata": {
        "id": "dPa3eBSEj0TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(pytorch_total_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDcTJHmFONne",
        "outputId": "2ff20e78-341b-460f-b177-6be32eefa7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6437576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Function\n",
        "def train(model,\n",
        "          optimizer,\n",
        "          train_loader,\n",
        "          valid_loader,\n",
        "          criterion = nn.CrossEntropyLoss(),\n",
        "          num_epochs = 5,\n",
        "          eval_every = len(train_dl) // 2,\n",
        "          file_path = '/content/drive/MyDrive/Colab Files/MovieReview',\n",
        "          best_valid_loss = float(\"Inf\")):\n",
        "    # print(valid_loader)\n",
        "    # initialize running values\n",
        "    running_loss = 0.0\n",
        "    valid_running_loss = 0.0\n",
        "    global_step = 0\n",
        "    train_loss_list = []\n",
        "    valid_loss_list = []\n",
        "    valid_acc_list = []\n",
        "    global_steps_list = []\n",
        "\n",
        "    # training loop\n",
        "    model.train()\n",
        "    tic = time.perf_counter()\n",
        "    for epoch in range(num_epochs):\n",
        "        for x, y, length in train_loader:   \n",
        "            x = x.long().to(device)\n",
        "            y = y.long().to(device)\n",
        "            length = length.long().to(device)\n",
        "            output = model(x, length)\n",
        "\n",
        "            loss = criterion(output, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # update running values\n",
        "            running_loss += loss.item()\n",
        "            global_step += 1\n",
        "\n",
        "            # evaluation step\n",
        "            # if global_step % eval_every == 0:\n",
        "            #     model.eval()\n",
        "            #     with torch.no_grad():                    \n",
        "            #       # validation loop\n",
        "            #       y_pred = []\n",
        "            #       y_true = []\n",
        "            #       for test_x, test_y, test_len in valid_loader:\n",
        "            #           test_x = test_x.long().to(device)\n",
        "            #           test_y = test_y.long().to(device)\n",
        "            #           test_len = test_len.long().to(device)\n",
        "            #           test_output = model(test_x, test_len)\n",
        "            #           loss = criterion(test_output, test_y)\n",
        "            #           valid_running_loss += loss.item()\n",
        "            #           output = torch.argmax(test_output, dim=1)\n",
        "            #           y_pred.extend(output.tolist())\n",
        "            #           y_true.extend(test_y.tolist())\n",
        "    \n",
        "            #     # evaluation\n",
        "            #     accuracy = accuracy_score(y_true, y_pred)\n",
        "            #     average_train_loss = running_loss / eval_every\n",
        "            #     average_valid_loss = valid_running_loss / len(valid_loader)\n",
        "            #     train_loss_list.append(average_train_loss)\n",
        "            #     valid_loss_list.append(average_valid_loss)\n",
        "            #     valid_acc_list.append(accuracy)\n",
        "            #     global_steps_list.append(global_step)\n",
        "\n",
        "            #     # resetting running values\n",
        "            #     running_loss = 0.0                \n",
        "            #     valid_running_loss = 0.0\n",
        "            #     model.train()\n",
        "\n",
        "            #     # print progress\n",
        "            #     print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}, Valid Acc: {:.4f}'\n",
        "            #           .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
        "            #                   average_train_loss, average_valid_loss, accuracy))\n",
        "                \n",
        "            #     # checkpoint\n",
        "            #     if best_valid_loss > average_valid_loss:\n",
        "            #         best_valid_loss = average_valid_loss\n",
        "            #         save_checkpoint(file_path + '/model.pt', model, optimizer, best_valid_loss)\n",
        "            #         save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "    toc = time.perf_counter()\n",
        "    print(f'Efficiency: {(toc - tic) / epoch} s/epoch')\n",
        "\n",
        "    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "    df = pandas.DataFrame(data={'train_loss': train_loss_list, 'valid_acc': valid_acc_list})\n",
        "    print('Finished Training!')\n",
        "    return df\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for test_x, test_y, test_len in test_loader:\n",
        "        test_x = test_x.long().to(device)\n",
        "        test_y = test_y.long().to(device)\n",
        "        test_len = test_len.long().to(device)\n",
        "        test_output = model(test_x, test_len)\n",
        "        output = torch.argmax(test_output, dim=1)\n",
        "        y_pred.extend(output.tolist())\n",
        "        y_true.extend(test_y.tolist())\n",
        "    \n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy is {accuracy}')\n",
        "    return y_pred, accuracy\n",
        "\n",
        "\n",
        "accuracies = []\n",
        "for i in range(1):\n",
        "  model = LSTM(len(vocab2), W, len(label_to_idx)).to(device)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
        "  data_df = train(model, optimizer, train_dl, test_dl, num_epochs=20, file_path='/content/drive/MyDrive/Colab Files/R8-lstm')\n",
        "  data_df.to_csv('/content/drive/MyDrive/Colab Files/R8-lstm/training_info.csv')\n",
        "  # load_checkpoint('/content/drive/MyDrive/Colab Files/R8-lstm/model.pt', model, optimizer)\n",
        "  y_pred, acc = evaluate(model, test_dl)\n",
        "  accuracies.append(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzLsDYaBj2ab",
        "outputId": "88170988-865f-4aa3-994a-6171da3c3ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Efficiency: 3.8318069294736663 s/epoch\n",
            "Model saved to ==> /content/drive/MyDrive/Colab Files/R8-lstm/metrics.pt\n",
            "Finished Training!\n",
            "Accuracy is 0.9529465509365007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1988nFSekZK",
        "outputId": "f7a90e1c-7355-462f-85e7-7cb37ed9046e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7791221159257175,\n",
              " 0.7726505346088914,\n",
              " 0.7732132808103546,\n",
              " 0.7647720877884074,\n",
              " 0.7760270118176702]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(accuracies))\n",
        "print(np.std(accuracies))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYDUyKf9Fu9I",
        "outputId": "008520a2-7b84-4c4c-9c9f-1605a9256b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7731570061902083\n",
            "0.004783011673804318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = LSTM(len(vocab2), W, len(label_to_idx)).to(device)\n",
        "# optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
        "\n",
        "load_checkpoint('/content/drive/MyDrive/Colab Files/MovieReview/model.pt', best_model, optimizer)\n",
        "pred = pandas.DataFrame({'pred': evaluate(best_model, test_dl)})\n",
        "pred.to_csv('/content/drive/MyDrive/Colab Files/MovieReview/mr-bilstm-pred.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPnP7WjTVPBa",
        "outputId": "d6b85254-0531-4f62-c1dc-3f439e0aa3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from <== /content/drive/MyDrive/Colab Files/MovieReview/model.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 0.7664603263927968\n"
          ]
        }
      ]
    }
  ]
}